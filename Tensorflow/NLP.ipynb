{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from keras.datasets import imdb\r\n",
    "from keras.preprocessing import sequence\r\n",
    "import tensorflow as tf\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "vocabSize = 88584\r\n",
    "maxLen = 250\r\n",
    "batchSize = 64\r\n",
    "\r\n",
    "(trainData, trainLabel), (testData, testLabel) = imdb.load_data(num_words= vocabSize)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "trainData[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are basically adding padding to the data in form of blanks words to make the sequences of uniform lenght and"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trainData = sequence.pad_sequences(trainData, maxLen)\r\n",
    "testData = sequence.pad_sequences(testData, maxLen)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first we have a embedding layer then a LSTM layer afterwards that finally feed into a dense node \r\n",
    "32 stands for the output dimensions of the vector generator by the embedded layer. We can change it if we want."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.Embedding(vocabSize, 32),\r\n",
    "    tf.keras.layers.LSTM(32),\r\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          2834688   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\r\n",
    "history = model.fit(trainData, trainLabel, epochs=10, validation_split=0.2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 59s 91ms/step - loss: 0.4289 - acc: 0.8059 - val_loss: 0.3116 - val_acc: 0.8682\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 68s 108ms/step - loss: 0.2421 - acc: 0.9079 - val_loss: 0.2801 - val_acc: 0.8912\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 59s 95ms/step - loss: 0.1887 - acc: 0.9301 - val_loss: 0.2794 - val_acc: 0.8932\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.1540 - acc: 0.9437 - val_loss: 0.2897 - val_acc: 0.8834\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 83s 132ms/step - loss: 0.1327 - acc: 0.9541 - val_loss: 0.3436 - val_acc: 0.8822\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.1160 - acc: 0.9610 - val_loss: 0.3039 - val_acc: 0.8918\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.1036 - acc: 0.9650 - val_loss: 0.3435 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 84s 134ms/step - loss: 0.0913 - acc: 0.9702 - val_loss: 0.3450 - val_acc: 0.8896\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 84s 134ms/step - loss: 0.0785 - acc: 0.9739 - val_loss: 0.4135 - val_acc: 0.8752\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 84s 134ms/step - loss: 0.0734 - acc: 0.9765 - val_loss: 0.3642 - val_acc: 0.8778\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "result = model.evaluate(testData, testLabel)\r\n",
    "print(result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "782/782 [==============================] - 17s 21ms/step - loss: 0.4138 - acc: 0.8545\n",
      "[0.413835346698761, 0.8545200228691101]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to make prediction but as our training data was also preprocessed therefore we need to do the same and if we directly pass them then the model will think its a different type of data and we will not get very accurate results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "wordIndex = imdb.get_word_index()\r\n",
    "\r\n",
    "def encode(text):\r\n",
    "    token = tf.keras.preprocessing.text.text_to_word_sequence(text)\r\n",
    "    token = [wordIndex[word] if word in wordIndex else 0 for word in token]\r\n",
    "    return sequence.pad_sequences([token], maxLen)[0]\r\n",
    "text=\"that movie was just amazing, so amazing\"\r\n",
    "encoded = encode(text)\r\n",
    "print(encoded)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our decoding function for converting the numerical output to string formate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "reverse = {value: key for (key, value) in wordIndex.items()}\r\n",
    "\r\n",
    "def decode(i):\r\n",
    "    text = \"\"\r\n",
    "    for num in i:\r\n",
    "        if num != 0:\r\n",
    "            text += reverse[num] + \" \"\r\n",
    "    return text[:-1]\r\n",
    "\r\n",
    "print(decode(encoded))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def predict(text):\r\n",
    "    encoding = encode(text)\r\n",
    "    pred = np.zeros((1,250))\r\n",
    "    pred[0] = encoding \r\n",
    "    result = model.predict(pred)\r\n",
    "    print(result[0])\r\n",
    "\r\n",
    "positive  =\"That very good movie was so awesome! I really loved it and would watch it again because it eas great\"\r\n",
    "predict(positive)\r\n",
    "\r\n",
    "negative = \"That movie sucked. I hated and wouldn't watch it again. Was shit one of the worst things I've ever wached\"\r\n",
    "predict(negative)\r\n",
    "negative = \"shit shit shit shit shit shit shit shit shit shit shit shit shit shit \"\r\n",
    "predict(negative)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.71440643]\n",
      "[0.33813304]\n",
      "[0.00314721]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "8934747c923e747831e0f17a40e9012e1def99ed1de5f3713c68cc42b4047f71"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}